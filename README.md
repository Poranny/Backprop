# Backprop

Simple implementation of a feedforward Fully Connected Neural Network with backpropagation training and much more, developed from scratch.

## Features

- Neurons, layers, and connections with weights and biases  
- Supports common activation functions: ReLU, Sigmoid, Tanh, Identity 
- Forward pass and backpropagation  
- Input/output normalization  
- MSE loss calculation
- Visualization for 1D and 2D inputs
- Minimal dependencies, easy to extend

<div style="display: flex; justify-content: space-between; align-items: center;">
  <img src="visualizations/plot1.png" alt="Plot1" style="display: block; height:395px" />
  <img src="visualizations/plot3.png" alt="Plot3" style="display: block; height:395px" />
</div>
